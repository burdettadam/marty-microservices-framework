"""
Configuration for Caching Service
"""

import os
from typing import List, Optional, Dict, Any, Union
from enum import Enum
from dataclasses import dataclass, field
from datetime import timedelta

from src.{{service_package}}.app.core.config import BaseServiceConfig


class CachePattern(Enum):
    """Cache patterns."""
    CACHE_ASIDE = "cache_aside"
    WRITE_THROUGH = "write_through"
    WRITE_BEHIND = "write_behind"
    REFRESH_AHEAD = "refresh_ahead"


class EvictionPolicy(Enum):
    """Cache eviction policies."""
    LRU = "lru"
    LFU = "lfu"
    FIFO = "fifo"
    TTL = "ttl"
    RANDOM = "random"


class SerializationFormat(Enum):
    """Serialization formats."""
    JSON = "json"
    PICKLE = "pickle"
    MSGPACK = "msgpack"
    PROTOBUF = "protobuf"


@dataclass
class CacheConfiguration:
    """Cache configuration settings."""
    name: str
    pattern: CachePattern
    ttl_seconds: Optional[int] = None
    max_size: Optional[int] = None
    eviction_policy: EvictionPolicy = EvictionPolicy.LRU
    serialization_format: SerializationFormat = SerializationFormat.JSON
    compression_enabled: bool = False
    encryption_enabled: bool = False
    namespace: Optional[str] = None
    tags: List[str] = field(default_factory=list)

    def get_cache_key_prefix(self) -> str:
        """Get cache key prefix for this configuration."""
        parts = []
        if self.namespace:
            parts.append(self.namespace)
        parts.append(self.name)
        return ":".join(parts)


class {{service_class}}CachingServiceConfig(BaseServiceConfig):
    """Configuration for {{service_class}} Caching Service."""

    def __init__(self):
        """Initialize caching service configuration."""
        super().__init__()

        # Service identification
        self.service_name = os.getenv("SERVICE_NAME", "{{service_name}}")
        self.service_version = os.getenv("SERVICE_VERSION", "1.0.0")

        # Server configuration
        self.host = os.getenv("HOST", "0.0.0.0")
        self.port = int(os.getenv("PORT", "8000"))

        # Redis configuration
        self.redis_host = os.getenv("REDIS_HOST", "localhost")
        self.redis_port = int(os.getenv("REDIS_PORT", "6379"))
        self.redis_db = int(os.getenv("REDIS_DB", "0"))
        self.redis_password = os.getenv("REDIS_PASSWORD")
        self.redis_username = os.getenv("REDIS_USERNAME")
        self.redis_ssl_enabled = os.getenv("REDIS_SSL_ENABLED", "false").lower() == "true"
        self.redis_ssl_cert_reqs = os.getenv("REDIS_SSL_CERT_REQS", "required")
        self.redis_ssl_ca_certs = os.getenv("REDIS_SSL_CA_CERTS")
        self.redis_ssl_certfile = os.getenv("REDIS_SSL_CERTFILE")
        self.redis_ssl_keyfile = os.getenv("REDIS_SSL_KEYFILE")

        # Connection pooling
        self.redis_max_connections = int(os.getenv("REDIS_MAX_CONNECTIONS", "100"))
        self.redis_connection_timeout = int(os.getenv("REDIS_CONNECTION_TIMEOUT", "30"))
        self.redis_socket_timeout = int(os.getenv("REDIS_SOCKET_TIMEOUT", "30"))
        self.redis_retry_on_timeout = os.getenv("REDIS_RETRY_ON_TIMEOUT", "true").lower() == "true"

        # Cache configuration
        self.default_cache_ttl = int(os.getenv("DEFAULT_CACHE_TTL", "3600"))  # 1 hour
        self.default_cache_pattern = CachePattern(os.getenv("DEFAULT_CACHE_PATTERN", "cache_aside"))
        self.default_eviction_policy = EvictionPolicy(os.getenv("DEFAULT_EVICTION_POLICY", "lru"))
        self.default_serialization_format = SerializationFormat(os.getenv("DEFAULT_SERIALIZATION_FORMAT", "json"))

        # Cache size limits
        self.max_cache_size_mb = int(os.getenv("MAX_CACHE_SIZE_MB", "1024"))  # 1GB
        self.max_key_size_bytes = int(os.getenv("MAX_KEY_SIZE_BYTES", "1024"))  # 1KB
        self.max_value_size_mb = int(os.getenv("MAX_VALUE_SIZE_MB", "100"))  # 100MB

        # Cache behavior
        self.enable_cache_compression = os.getenv("ENABLE_CACHE_COMPRESSION", "false").lower() == "true"
        self.enable_cache_encryption = os.getenv("ENABLE_CACHE_ENCRYPTION", "false").lower() == "true"
        self.cache_encryption_key = os.getenv("CACHE_ENCRYPTION_KEY")
        self.enable_cache_versioning = os.getenv("ENABLE_CACHE_VERSIONING", "true").lower() == "true"

        # Distributed locking
        self.enable_distributed_locking = os.getenv("ENABLE_DISTRIBUTED_LOCKING", "true").lower() == "true"
        self.lock_default_ttl = int(os.getenv("LOCK_DEFAULT_TTL", "30"))  # 30 seconds
        self.lock_retry_attempts = int(os.getenv("LOCK_RETRY_ATTEMPTS", "3"))
        self.lock_retry_delay_ms = int(os.getenv("LOCK_RETRY_DELAY_MS", "100"))
        self.lock_extend_ttl = int(os.getenv("LOCK_EXTEND_TTL", "10"))  # 10 seconds

        # Cache invalidation
        self.enable_cache_invalidation = os.getenv("ENABLE_CACHE_INVALIDATION", "true").lower() == "true"
        self.cache_invalidation_channel = os.getenv("CACHE_INVALIDATION_CHANNEL", "cache_invalidation")
        self.enable_tag_based_invalidation = os.getenv("ENABLE_TAG_BASED_INVALIDATION", "true").lower() == "true"

        # Cache warming
        self.enable_cache_warming = os.getenv("ENABLE_CACHE_WARMING", "false").lower() == "true"
        self.cache_warming_batch_size = int(os.getenv("CACHE_WARMING_BATCH_SIZE", "100"))
        self.cache_warming_interval_seconds = int(os.getenv("CACHE_WARMING_INTERVAL_SECONDS", "300"))  # 5 minutes

        # Write-behind configuration
        self.write_behind_batch_size = int(os.getenv("WRITE_BEHIND_BATCH_SIZE", "100"))
        self.write_behind_flush_interval_ms = int(os.getenv("WRITE_BEHIND_FLUSH_INTERVAL_MS", "5000"))  # 5 seconds
        self.write_behind_max_retry_attempts = int(os.getenv("WRITE_BEHIND_MAX_RETRY_ATTEMPTS", "3"))
        self.write_behind_retry_delay_ms = int(os.getenv("WRITE_BEHIND_RETRY_DELAY_MS", "1000"))

        # Refresh-ahead configuration
        self.refresh_ahead_threshold_ratio = float(os.getenv("REFRESH_AHEAD_THRESHOLD_RATIO", "0.8"))  # 80% of TTL
        self.refresh_ahead_max_concurrent = int(os.getenv("REFRESH_AHEAD_MAX_CONCURRENT", "10"))

        # Monitoring and metrics
        self.enable_cache_metrics = os.getenv("ENABLE_CACHE_METRICS", "true").lower() == "true"
        self.cache_metrics_collection_interval = int(os.getenv("CACHE_METRICS_COLLECTION_INTERVAL", "60"))  # 1 minute
        self.enable_cache_hit_rate_tracking = os.getenv("ENABLE_CACHE_HIT_RATE_TRACKING", "true").lower() == "true"

        # Performance tuning
        self.enable_pipelining = os.getenv("ENABLE_PIPELINING", "true").lower() == "true"
        self.pipeline_batch_size = int(os.getenv("PIPELINE_BATCH_SIZE", "100"))
        self.enable_connection_multiplexing = os.getenv("ENABLE_CONNECTION_MULTIPLEXING", "true").lower() == "true"

        # Rate limiting
        self.enable_rate_limiting = os.getenv("ENABLE_RATE_LIMITING", "true").lower() == "true"
        self.default_rate_limit = int(os.getenv("DEFAULT_RATE_LIMIT", "1000"))  # requests per minute
        self.rate_limit_window = int(os.getenv("RATE_LIMIT_WINDOW", "60"))  # seconds

        # Circuit breaker
        self.enable_circuit_breaker = os.getenv("ENABLE_CIRCUIT_BREAKER", "true").lower() == "true"
        self.circuit_breaker_failure_threshold = int(os.getenv("CIRCUIT_BREAKER_FAILURE_THRESHOLD", "5"))
        self.circuit_breaker_timeout_seconds = int(os.getenv("CIRCUIT_BREAKER_TIMEOUT_SECONDS", "60"))
        self.circuit_breaker_reset_timeout = int(os.getenv("CIRCUIT_BREAKER_RESET_TIMEOUT", "30"))

        # Predefined cache configurations
        self._cache_configurations = self._load_cache_configurations()

    def get_redis_config(self) -> Dict[str, Any]:
        """Get Redis connection configuration."""
        config = {
            "host": self.redis_host,
            "port": self.redis_port,
            "db": self.redis_db,
            "max_connections": self.redis_max_connections,
            "socket_timeout": self.redis_connection_timeout,
            "socket_connect_timeout": self.redis_socket_timeout,
            "retry_on_timeout": self.redis_retry_on_timeout,
            "decode_responses": False  # We handle encoding/decoding manually
        }

        # Add authentication if provided
        if self.redis_username:
            config["username"] = self.redis_username
        if self.redis_password:
            config["password"] = self.redis_password

        # Add SSL configuration if enabled
        if self.redis_ssl_enabled:
            config["ssl"] = True
            if self.redis_ssl_cert_reqs:
                import ssl
                config["ssl_cert_reqs"] = getattr(ssl, self.redis_ssl_cert_reqs.upper())
            if self.redis_ssl_ca_certs:
                config["ssl_ca_certs"] = self.redis_ssl_ca_certs
            if self.redis_ssl_certfile:
                config["ssl_certfile"] = self.redis_ssl_certfile
            if self.redis_ssl_keyfile:
                config["ssl_keyfile"] = self.redis_ssl_keyfile

        return config

    def get_cache_configuration(self, cache_name: str) -> Optional[CacheConfiguration]:
        """Get cache configuration by name."""
        return self._cache_configurations.get(cache_name)

    def register_cache_configuration(self, config: CacheConfiguration) -> None:
        """Register a new cache configuration."""
        self._cache_configurations[config.name] = config

    def list_cache_configurations(self) -> List[str]:
        """List all registered cache configuration names."""
        return list(self._cache_configurations.keys())

    def _load_cache_configurations(self) -> Dict[str, CacheConfiguration]:
        """Load predefined cache configurations."""
        configurations = {}

        # Default cache configuration
        configurations["default"] = CacheConfiguration(
            name="default",
            pattern=self.default_cache_pattern,
            ttl_seconds=self.default_cache_ttl,
            eviction_policy=self.default_eviction_policy,
            serialization_format=self.default_serialization_format,
            compression_enabled=self.enable_cache_compression,
            encryption_enabled=self.enable_cache_encryption
        )

        # Session cache (short-lived, LRU)
        configurations["session"] = CacheConfiguration(
            name="session",
            pattern=CachePattern.CACHE_ASIDE,
            ttl_seconds=1800,  # 30 minutes
            max_size=10000,
            eviction_policy=EvictionPolicy.LRU,
            serialization_format=SerializationFormat.JSON,
            namespace="sessions"
        )

        # User data cache (medium-lived, LFU)
        configurations["user_data"] = CacheConfiguration(
            name="user_data",
            pattern=CachePattern.WRITE_THROUGH,
            ttl_seconds=7200,  # 2 hours
            max_size=50000,
            eviction_policy=EvictionPolicy.LFU,
            serialization_format=SerializationFormat.JSON,
            namespace="users",
            tags=["user", "profile"]
        )

        # Configuration cache (long-lived, rarely changes)
        configurations["config"] = CacheConfiguration(
            name="config",
            pattern=CachePattern.REFRESH_AHEAD,
            ttl_seconds=86400,  # 24 hours
            max_size=1000,
            eviction_policy=EvictionPolicy.TTL,
            serialization_format=SerializationFormat.JSON,
            namespace="config",
            tags=["configuration", "settings"]
        )

        # API response cache (short-lived, high volume)
        configurations["api_response"] = CacheConfiguration(
            name="api_response",
            pattern=CachePattern.CACHE_ASIDE,
            ttl_seconds=300,  # 5 minutes
            max_size=100000,
            eviction_policy=EvictionPolicy.LRU,
            serialization_format=SerializationFormat.JSON,
            compression_enabled=True,
            namespace="api",
            tags=["api", "response"]
        )

        # Database query cache (write-behind for analytics)
        configurations["db_query"] = CacheConfiguration(
            name="db_query",
            pattern=CachePattern.WRITE_BEHIND,
            ttl_seconds=3600,  # 1 hour
            max_size=25000,
            eviction_policy=EvictionPolicy.LRU,
            serialization_format=SerializationFormat.MSGPACK,
            compression_enabled=True,
            namespace="db",
            tags=["database", "query"]
        )

        # File cache (large objects, compressed)
        configurations["file"] = CacheConfiguration(
            name="file",
            pattern=CachePattern.CACHE_ASIDE,
            ttl_seconds=21600,  # 6 hours
            max_size=1000,
            eviction_policy=EvictionPolicy.LFU,
            serialization_format=SerializationFormat.PICKLE,
            compression_enabled=True,
            namespace="files",
            tags=["file", "storage"]
        )

        # Temporary cache (very short-lived, FIFO)
        configurations["temp"] = CacheConfiguration(
            name="temp",
            pattern=CachePattern.CACHE_ASIDE,
            ttl_seconds=60,  # 1 minute
            max_size=5000,
            eviction_policy=EvictionPolicy.FIFO,
            serialization_format=SerializationFormat.JSON,
            namespace="temp",
            tags=["temporary"]
        )

        return configurations

    def get_lock_configuration(self) -> Dict[str, Any]:
        """Get distributed lock configuration."""
        return {
            "default_ttl": self.lock_default_ttl,
            "retry_attempts": self.lock_retry_attempts,
            "retry_delay_ms": self.lock_retry_delay_ms,
            "extend_ttl": self.lock_extend_ttl,
            "enabled": self.enable_distributed_locking
        }

    def get_write_behind_configuration(self) -> Dict[str, Any]:
        """Get write-behind cache configuration."""
        return {
            "batch_size": self.write_behind_batch_size,
            "flush_interval_ms": self.write_behind_flush_interval_ms,
            "max_retry_attempts": self.write_behind_max_retry_attempts,
            "retry_delay_ms": self.write_behind_retry_delay_ms
        }

    def get_refresh_ahead_configuration(self) -> Dict[str, Any]:
        """Get refresh-ahead cache configuration."""
        return {
            "threshold_ratio": self.refresh_ahead_threshold_ratio,
            "max_concurrent": self.refresh_ahead_max_concurrent
        }

    def get_circuit_breaker_configuration(self) -> Dict[str, Any]:
        """Get circuit breaker configuration."""
        return {
            "enabled": self.enable_circuit_breaker,
            "failure_threshold": self.circuit_breaker_failure_threshold,
            "timeout_seconds": self.circuit_breaker_timeout_seconds,
            "reset_timeout": self.circuit_breaker_reset_timeout
        }

    def validate_configuration(self) -> List[str]:
        """Validate the configuration and return any errors."""
        errors = []

        # Validate Redis connection
        if not self.redis_host:
            errors.append("Redis host is required")

        if self.redis_port <= 0 or self.redis_port > 65535:
            errors.append("Redis port must be between 1 and 65535")

        # Validate cache settings
        if self.default_cache_ttl < 0:
            errors.append("Default cache TTL cannot be negative")

        if self.max_cache_size_mb <= 0:
            errors.append("Max cache size must be positive")

        if self.max_key_size_bytes <= 0:
            errors.append("Max key size must be positive")

        if self.max_value_size_mb <= 0:
            errors.append("Max value size must be positive")

        # Validate encryption settings
        if self.enable_cache_encryption and not self.cache_encryption_key:
            errors.append("Cache encryption key is required when encryption is enabled")

        # Validate lock settings
        if self.lock_default_ttl <= 0:
            errors.append("Lock default TTL must be positive")

        if self.lock_retry_attempts < 0:
            errors.append("Lock retry attempts cannot be negative")

        # Validate write-behind settings
        if self.write_behind_batch_size <= 0:
            errors.append("Write-behind batch size must be positive")

        if self.write_behind_flush_interval_ms <= 0:
            errors.append("Write-behind flush interval must be positive")

        # Validate refresh-ahead settings
        if not 0 < self.refresh_ahead_threshold_ratio < 1:
            errors.append("Refresh-ahead threshold ratio must be between 0 and 1")

        if self.refresh_ahead_max_concurrent <= 0:
            errors.append("Refresh-ahead max concurrent must be positive")

        return errors


# Global configuration instance
_config: Optional[{{service_class}}CachingServiceConfig] = None


def get_config() -> {{service_class}}CachingServiceConfig:
    """Get the global configuration instance."""
    global _config
    if _config is None:
        _config = {{service_class}}CachingServiceConfig()
    return _config
