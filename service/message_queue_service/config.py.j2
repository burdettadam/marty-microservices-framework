"""
{{service_name}} Message Queue Service Configuration
"""

import os
from typing import List, Optional, Dict, Any, Union
from enum import Enum

from marty_common.config_base import GRPCServiceConfig


class MessageBrokerType(str, Enum):
    """Message broker type enumeration."""
    KAFKA = "kafka"
    RABBITMQ = "rabbitmq"
    REDIS = "redis"
    IN_MEMORY = "in_memory"


class SerializationFormat(str, Enum):
    """Message serialization format enumeration."""
    JSON = "json"
    AVRO = "avro"
    PROTOBUF = "protobuf"
    MSGPACK = "msgpack"


class DeliveryGuarantee(str, Enum):
    """Message delivery guarantee enumeration."""
    AT_MOST_ONCE = "at_most_once"
    AT_LEAST_ONCE = "at_least_once"
    EXACTLY_ONCE = "exactly_once"


class {{service_class}}ServiceConfig(GRPCServiceConfig):
    """Configuration for {{service_name}} Message Queue Service."""

    # Message Broker Configuration
    message_broker_type: MessageBrokerType = MessageBrokerType(
        os.environ.get("MESSAGE_BROKER_TYPE", "kafka")
    )
    default_serialization_format: SerializationFormat = SerializationFormat(
        os.environ.get("DEFAULT_SERIALIZATION_FORMAT", "json")
    )
    default_delivery_guarantee: DeliveryGuarantee = DeliveryGuarantee(
        os.environ.get("DEFAULT_DELIVERY_GUARANTEE", "at_least_once")
    )

    # Kafka Configuration
    kafka_enabled: bool = os.environ.get("KAFKA_ENABLED", "true").lower() == "true"
    kafka_bootstrap_servers: List[str] = os.environ.get(
        "KAFKA_BOOTSTRAP_SERVERS", "localhost:9092"
    ).split(",")
    kafka_security_protocol: str = os.environ.get("KAFKA_SECURITY_PROTOCOL", "PLAINTEXT")
    kafka_sasl_mechanism: Optional[str] = os.environ.get("KAFKA_SASL_MECHANISM")
    kafka_sasl_username: Optional[str] = os.environ.get("KAFKA_SASL_USERNAME")
    kafka_sasl_password: Optional[str] = os.environ.get("KAFKA_SASL_PASSWORD")
    kafka_ssl_cafile: Optional[str] = os.environ.get("KAFKA_SSL_CAFILE")
    kafka_ssl_certfile: Optional[str] = os.environ.get("KAFKA_SSL_CERTFILE")
    kafka_ssl_keyfile: Optional[str] = os.environ.get("KAFKA_SSL_KEYFILE")

    # Kafka Producer Configuration
    kafka_producer_acks: str = os.environ.get("KAFKA_PRODUCER_ACKS", "all")
    kafka_producer_retries: int = int(os.environ.get("KAFKA_PRODUCER_RETRIES", "3"))
    kafka_producer_batch_size: int = int(os.environ.get("KAFKA_PRODUCER_BATCH_SIZE", "16384"))
    kafka_producer_linger_ms: int = int(os.environ.get("KAFKA_PRODUCER_LINGER_MS", "10"))
    kafka_producer_buffer_memory: int = int(os.environ.get("KAFKA_PRODUCER_BUFFER_MEMORY", "33554432"))
    kafka_producer_compression_type: str = os.environ.get("KAFKA_PRODUCER_COMPRESSION_TYPE", "snappy")
    kafka_producer_max_request_size: int = int(os.environ.get("KAFKA_PRODUCER_MAX_REQUEST_SIZE", "1048576"))
    kafka_producer_request_timeout_ms: int = int(os.environ.get("KAFKA_PRODUCER_REQUEST_TIMEOUT_MS", "30000"))
    kafka_producer_enable_idempotence: bool = os.environ.get("KAFKA_PRODUCER_ENABLE_IDEMPOTENCE", "true").lower() == "true"

    # Kafka Consumer Configuration
    kafka_consumer_group_id: str = os.environ.get("KAFKA_CONSUMER_GROUP_ID", "{{service_package}}-consumer-group")
    kafka_consumer_auto_offset_reset: str = os.environ.get("KAFKA_CONSUMER_AUTO_OFFSET_RESET", "earliest")
    kafka_consumer_enable_auto_commit: bool = os.environ.get("KAFKA_CONSUMER_ENABLE_AUTO_COMMIT", "false").lower() == "true"
    kafka_consumer_auto_commit_interval_ms: int = int(os.environ.get("KAFKA_CONSUMER_AUTO_COMMIT_INTERVAL_MS", "5000"))
    kafka_consumer_session_timeout_ms: int = int(os.environ.get("KAFKA_CONSUMER_SESSION_TIMEOUT_MS", "30000"))
    kafka_consumer_heartbeat_interval_ms: int = int(os.environ.get("KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS", "3000"))
    kafka_consumer_max_poll_records: int = int(os.environ.get("KAFKA_CONSUMER_MAX_POLL_RECORDS", "500"))
    kafka_consumer_max_poll_interval_ms: int = int(os.environ.get("KAFKA_CONSUMER_MAX_POLL_INTERVAL_MS", "300000"))
    kafka_consumer_fetch_min_bytes: int = int(os.environ.get("KAFKA_CONSUMER_FETCH_MIN_BYTES", "1"))
    kafka_consumer_fetch_max_wait_ms: int = int(os.environ.get("KAFKA_CONSUMER_FETCH_MAX_WAIT_MS", "500"))

    # RabbitMQ Configuration
    rabbitmq_enabled: bool = os.environ.get("RABBITMQ_ENABLED", "false").lower() == "true"
    rabbitmq_url: str = os.environ.get("RABBITMQ_URL", "amqp://guest:guest@localhost:5672/")
    rabbitmq_connection_pool_size: int = int(os.environ.get("RABBITMQ_CONNECTION_POOL_SIZE", "10"))
    rabbitmq_channel_pool_size: int = int(os.environ.get("RABBITMQ_CHANNEL_POOL_SIZE", "20"))
    rabbitmq_heartbeat: int = int(os.environ.get("RABBITMQ_HEARTBEAT", "600"))
    rabbitmq_connection_timeout: int = int(os.environ.get("RABBITMQ_CONNECTION_TIMEOUT", "30"))
    rabbitmq_ssl_enabled: bool = os.environ.get("RABBITMQ_SSL_ENABLED", "false").lower() == "true"
    rabbitmq_ssl_verify: bool = os.environ.get("RABBITMQ_SSL_VERIFY", "true").lower() == "true"

    # RabbitMQ Exchange Configuration
    rabbitmq_default_exchange: str = os.environ.get("RABBITMQ_DEFAULT_EXCHANGE", "{{service_package}}.events")
    rabbitmq_exchange_type: str = os.environ.get("RABBITMQ_EXCHANGE_TYPE", "topic")
    rabbitmq_exchange_durable: bool = os.environ.get("RABBITMQ_EXCHANGE_DURABLE", "true").lower() == "true"
    rabbitmq_queue_durable: bool = os.environ.get("RABBITMQ_QUEUE_DURABLE", "true").lower() == "true"
    rabbitmq_message_ttl: Optional[int] = int(os.environ.get("RABBITMQ_MESSAGE_TTL", "0")) or None
    rabbitmq_dead_letter_exchange: Optional[str] = os.environ.get("RABBITMQ_DEAD_LETTER_EXCHANGE")

    # Redis Configuration (for Redis Streams or pub/sub)
    redis_enabled: bool = os.environ.get("REDIS_ENABLED", "false").lower() == "true"
    redis_url: str = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    redis_pool_size: int = int(os.environ.get("REDIS_POOL_SIZE", "10"))
    redis_stream_maxlen: int = int(os.environ.get("REDIS_STREAM_MAXLEN", "10000"))
    redis_consumer_group: str = os.environ.get("REDIS_CONSUMER_GROUP", "{{service_package}}-group")
    redis_consumer_name: str = os.environ.get("REDIS_CONSUMER_NAME", "{{service_package}}-consumer")

    # Message Processing Configuration
    message_retry_attempts: int = int(os.environ.get("MESSAGE_RETRY_ATTEMPTS", "3"))
    message_retry_delay_ms: int = int(os.environ.get("MESSAGE_RETRY_DELAY_MS", "1000"))
    message_retry_backoff_multiplier: float = float(os.environ.get("MESSAGE_RETRY_BACKOFF_MULTIPLIER", "2.0"))
    message_max_retry_delay_ms: int = int(os.environ.get("MESSAGE_MAX_RETRY_DELAY_MS", "30000"))
    message_processing_timeout_ms: int = int(os.environ.get("MESSAGE_PROCESSING_TIMEOUT_MS", "30000"))

    # Dead Letter Queue Configuration
    dlq_enabled: bool = os.environ.get("DLQ_ENABLED", "true").lower() == "true"
    dlq_topic_suffix: str = os.environ.get("DLQ_TOPIC_SUFFIX", ".dlq")
    dlq_max_retries: int = int(os.environ.get("DLQ_MAX_RETRIES", "5"))

    # Circuit Breaker Configuration
    circuit_breaker_enabled: bool = os.environ.get("CIRCUIT_BREAKER_ENABLED", "true").lower() == "true"
    circuit_breaker_failure_threshold: int = int(os.environ.get("CIRCUIT_BREAKER_FAILURE_THRESHOLD", "5"))
    circuit_breaker_timeout_ms: int = int(os.environ.get("CIRCUIT_BREAKER_TIMEOUT_MS", "60000"))
    circuit_breaker_half_open_max_calls: int = int(os.environ.get("CIRCUIT_BREAKER_HALF_OPEN_MAX_CALLS", "3"))

    # Metrics and Monitoring
    metrics_enabled: bool = os.environ.get("METRICS_ENABLED", "true").lower() == "true"
    metrics_include_message_content: bool = os.environ.get("METRICS_INCLUDE_MESSAGE_CONTENT", "false").lower() == "true"
    health_check_enabled: bool = os.environ.get("HEALTH_CHECK_ENABLED", "true").lower() == "true"
    health_check_interval_seconds: int = int(os.environ.get("HEALTH_CHECK_INTERVAL_SECONDS", "30"))

    # Message Schema Registry Configuration
    schema_registry_enabled: bool = os.environ.get("SCHEMA_REGISTRY_ENABLED", "false").lower() == "true"
    schema_registry_url: Optional[str] = os.environ.get("SCHEMA_REGISTRY_URL")
    schema_registry_auth_username: Optional[str] = os.environ.get("SCHEMA_REGISTRY_AUTH_USERNAME")
    schema_registry_auth_password: Optional[str] = os.environ.get("SCHEMA_REGISTRY_AUTH_PASSWORD")

    # Event Sourcing Configuration
    event_sourcing_enabled: bool = os.environ.get("EVENT_SOURCING_ENABLED", "false").lower() == "true"
    event_store_type: str = os.environ.get("EVENT_STORE_TYPE", "kafka")
    event_store_topic: str = os.environ.get("EVENT_STORE_TOPIC", "{{service_package}}.event-store")
    snapshot_frequency: int = int(os.environ.get("SNAPSHOT_FREQUENCY", "100"))

    # Message Filtering and Routing
    message_filtering_enabled: bool = os.environ.get("MESSAGE_FILTERING_ENABLED", "true").lower() == "true"
    content_based_routing_enabled: bool = os.environ.get("CONTENT_BASED_ROUTING_ENABLED", "true").lower() == "true"

    # Security Configuration
    message_encryption_enabled: bool = os.environ.get("MESSAGE_ENCRYPTION_ENABLED", "false").lower() == "true"
    message_encryption_key: Optional[str] = os.environ.get("MESSAGE_ENCRYPTION_KEY")
    message_signing_enabled: bool = os.environ.get("MESSAGE_SIGNING_ENABLED", "false").lower() == "true"
    message_signing_key: Optional[str] = os.environ.get("MESSAGE_SIGNING_KEY")

    # Rate Limiting Configuration
    rate_limiting_enabled: bool = os.environ.get("RATE_LIMITING_ENABLED", "true").lower() == "true"
    producer_rate_limit: int = int(os.environ.get("PRODUCER_RATE_LIMIT", "1000"))  # messages per second
    consumer_rate_limit: int = int(os.environ.get("CONSUMER_RATE_LIMIT", "500"))   # messages per second

    def get_kafka_config(self) -> Dict[str, Any]:
        """Get Kafka configuration dictionary."""
        config = {
            "bootstrap_servers": self.kafka_bootstrap_servers,
            "security_protocol": self.kafka_security_protocol,
        }

        if self.kafka_sasl_mechanism:
            config.update({
                "sasl_mechanism": self.kafka_sasl_mechanism,
                "sasl_plain_username": self.kafka_sasl_username,
                "sasl_plain_password": self.kafka_sasl_password,
            })

        if self.kafka_security_protocol in ["SSL", "SASL_SSL"]:
            ssl_config = {}
            if self.kafka_ssl_cafile:
                ssl_config["ssl_cafile"] = self.kafka_ssl_cafile
            if self.kafka_ssl_certfile:
                ssl_config["ssl_certfile"] = self.kafka_ssl_certfile
            if self.kafka_ssl_keyfile:
                ssl_config["ssl_keyfile"] = self.kafka_ssl_keyfile
            config.update(ssl_config)

        return config

    def get_kafka_producer_config(self) -> Dict[str, Any]:
        """Get Kafka producer configuration."""
        config = self.get_kafka_config()
        config.update({
            "acks": self.kafka_producer_acks,
            "retries": self.kafka_producer_retries,
            "batch_size": self.kafka_producer_batch_size,
            "linger_ms": self.kafka_producer_linger_ms,
            "buffer_memory": self.kafka_producer_buffer_memory,
            "compression_type": self.kafka_producer_compression_type,
            "max_request_size": self.kafka_producer_max_request_size,
            "request_timeout_ms": self.kafka_producer_request_timeout_ms,
            "enable_idempotence": self.kafka_producer_enable_idempotence,
        })
        return config

    def get_kafka_consumer_config(self) -> Dict[str, Any]:
        """Get Kafka consumer configuration."""
        config = self.get_kafka_config()
        config.update({
            "group_id": self.kafka_consumer_group_id,
            "auto_offset_reset": self.kafka_consumer_auto_offset_reset,
            "enable_auto_commit": self.kafka_consumer_enable_auto_commit,
            "auto_commit_interval_ms": self.kafka_consumer_auto_commit_interval_ms,
            "session_timeout_ms": self.kafka_consumer_session_timeout_ms,
            "heartbeat_interval_ms": self.kafka_consumer_heartbeat_interval_ms,
            "max_poll_records": self.kafka_consumer_max_poll_records,
            "max_poll_interval_ms": self.kafka_consumer_max_poll_interval_ms,
            "fetch_min_bytes": self.kafka_consumer_fetch_min_bytes,
            "fetch_max_wait_ms": self.kafka_consumer_fetch_max_wait_ms,
        })
        return config

    def get_rabbitmq_config(self) -> Dict[str, Any]:
        """Get RabbitMQ configuration dictionary."""
        return {
            "url": self.rabbitmq_url,
            "connection_pool_size": self.rabbitmq_connection_pool_size,
            "channel_pool_size": self.rabbitmq_channel_pool_size,
            "heartbeat": self.rabbitmq_heartbeat,
            "connection_timeout": self.rabbitmq_connection_timeout,
            "ssl_enabled": self.rabbitmq_ssl_enabled,
            "ssl_verify": self.rabbitmq_ssl_verify,
            "default_exchange": self.rabbitmq_default_exchange,
            "exchange_type": self.rabbitmq_exchange_type,
            "exchange_durable": self.rabbitmq_exchange_durable,
            "queue_durable": self.rabbitmq_queue_durable,
            "message_ttl": self.rabbitmq_message_ttl,
            "dead_letter_exchange": self.rabbitmq_dead_letter_exchange,
        }

    def get_redis_config(self) -> Dict[str, Any]:
        """Get Redis configuration dictionary."""
        return {
            "url": self.redis_url,
            "pool_size": self.redis_pool_size,
            "stream_maxlen": self.redis_stream_maxlen,
            "consumer_group": self.redis_consumer_group,
            "consumer_name": self.redis_consumer_name,
        }

    def get_consumer_configs(self) -> List[Dict[str, Any]]:
        """Get consumer configurations from environment."""
        # This would be populated based on your specific consumer needs
        # For now, return a basic configuration
        return [
            {
                "name": "default_consumer",
                "topics": [f"{{service_package}}.events"],
                "handler": "default_handler",
                "options": {
                    "max_workers": 5,
                    "batch_size": 100,
                    "timeout_ms": self.message_processing_timeout_ms
                }
            }
        ]

    def get_topic_configs(self) -> List[Dict[str, Any]]:
        """Get topic configurations."""
        return [
            {
                "name": f"{{service_package}}.events",
                "partitions": 3,
                "replication_factor": 1,
                "config": {
                    "retention.ms": "604800000",  # 7 days
                    "cleanup.policy": "delete",
                    "compression.type": "snappy"
                }
            },
            {
                "name": f"{{service_package}}.commands",
                "partitions": 1,
                "replication_factor": 1,
                "config": {
                    "retention.ms": "86400000",  # 1 day
                    "cleanup.policy": "delete"
                }
            }
        ]

    def validate_config(self) -> None:
        """Validate the configuration."""
        if not any([self.kafka_enabled, self.rabbitmq_enabled, self.redis_enabled]):
            raise ValueError("At least one message broker must be enabled")

        if self.kafka_enabled and not self.kafka_bootstrap_servers:
            raise ValueError("Kafka bootstrap servers must be configured when Kafka is enabled")

        if self.rabbitmq_enabled and not self.rabbitmq_url:
            raise ValueError("RabbitMQ URL must be configured when RabbitMQ is enabled")

        if self.redis_enabled and not self.redis_url:
            raise ValueError("Redis URL must be configured when Redis is enabled")

        if self.schema_registry_enabled and not self.schema_registry_url:
            raise ValueError("Schema registry URL must be configured when schema registry is enabled")

        if self.message_encryption_enabled and not self.message_encryption_key:
            raise ValueError("Message encryption key must be configured when encryption is enabled")

        if self.message_signing_enabled and not self.message_signing_key:
            raise ValueError("Message signing key must be configured when signing is enabled")
