# {{service_name}} Database Service

A comprehensive database service template with PostgreSQL, SQLAlchemy, and repository patterns.

## Features

- **PostgreSQL Integration**: Full PostgreSQL support with connection pooling
- **SQLAlchemy ORM**: Modern SQLAlchemy 2.0+ with declarative models
- **Repository Pattern**: Clean separation of database operations
- **Audit Logging**: Complete audit trail for all data changes
- **Database Migrations**: Alembic integration for schema management
- **Health Checks**: Database connectivity monitoring
- **Transaction Management**: Proper transaction handling with rollback support
- **Soft Deletes**: Safe deletion with recovery capabilities
- **Search & Pagination**: Built-in search and pagination support

## Quick Start

### 1. Configure Database

Update your configuration:

```python
# config.py
DATABASE_URL = "postgresql://user:password@localhost:5432/{{service_package}}_db"
DATABASE_POOL_SIZE = 10
DATABASE_MAX_OVERFLOW = 20
```

### 2. Run Migrations

```bash
# Initialize Alembic (first time only)
alembic init alembic

# Create initial migration
alembic revision --autogenerate -m "Initial migration"

# Apply migrations
alembic upgrade head
```

### 3. Use Repository Pattern

```python
from src.{{service_package}}.app.core.database import get_database_manager
from src.{{service_package}}.app.repositories import get_entity_repository

# Get database manager and repository
db_manager = get_database_manager()
entity_repo = get_entity_repository()

# Create entity with transaction
with db_manager.get_transaction() as session:
    entity = entity_repo.create(
        session=session,
        name="My Entity",
        description="A sample entity",
        status="active"
    )
    print(f"Created entity: {entity.id}")

# Query entities
with db_manager.get_session() as session:
    entities = entity_repo.get_all(session, limit=10)
    for entity in entities:
        print(f"Entity: {entity.name}")
```

## Database Schema

### Entities Table
- `id` (UUID): Primary key
- `name` (String): Entity name
- `description` (Text): Optional description
- `external_id` (String): Optional external identifier
- `status` (String): Entity status
- `metadata_` (JSON): Additional metadata
- `created_at`, `updated_at`: Timestamps
- `deleted_at`: Soft delete timestamp
- `version`: Optimistic locking version

### Attributes Table
- `id` (UUID): Primary key
- `entity_id` (UUID): Foreign key to entities
- `attribute_name` (String): Attribute name
- `attribute_value` (Text): Attribute value
- `attribute_type` (String): Value type
- `created_at`, `updated_at`: Timestamps
- `deleted_at`: Soft delete timestamp
- `version`: Optimistic locking version

### Audit Logs Table
- `id` (UUID): Primary key
- `entity_id` (UUID): Related entity
- `entity_type` (String): Type of entity
- `action` (String): Action performed
- `old_values`, `new_values` (JSON): Change tracking
- `user_id`, `session_id`: User context
- `ip_address`, `user_agent`: Request context
- `timestamp`: When change occurred
- `additional_info` (JSON): Extra information

## Repository Operations

### Entity Repository

```python
# Create
entity = entity_repo.create(
    session=session,
    name="Product",
    description="A sample product",
    status="active",
    external_id="prod-123",
    metadata_={"category": "electronics"}
)

# Read
entity = entity_repo.get_by_id(session, entity_id)
entities = entity_repo.get_all(session, skip=0, limit=50)
entities = entity_repo.search(session, "product", limit=10)

# Update
updated_entity = entity_repo.update(
    session=session,
    entity_id=entity_id,
    name="Updated Product",
    status="inactive"
)

# Delete (soft by default)
success = entity_repo.delete(session, entity_id, soft_delete=True)

# Count
total = entity_repo.count(session)
```

### Attribute Repository

```python
# Create attribute
attribute = attribute_repo.create(
    session=session,
    entity_id=entity_id,
    attribute_name="color",
    attribute_value="blue",
    attribute_type="string"
)

# Get attributes for entity
attributes = attribute_repo.get_by_entity_id(session, entity_id)

# Update attribute
updated_attr = attribute_repo.update(
    session=session,
    attribute_id=attribute_id,
    attribute_value="red"
)
```

### Audit Repository

```python
# Log changes (automatic in service layer)
audit_log = audit_repo.log_change(
    session=session,
    entity_id=entity_id,
    entity_type="{{service_class}}Entity",
    action="UPDATE",
    old_values={"status": "active"},
    new_values={"status": "inactive"},
    user_id="user123",
    session_id="session456"
)

# Get audit trail
audit_trail = audit_repo.get_audit_trail(session, entity_id)
for log in audit_trail:
    print(f"{log.timestamp}: {log.action} by {log.user_id}")
```

## Database Manager

```python
from src.{{service_package}}.app.core.database import get_database_manager

db_manager = get_database_manager()

# Session management
with db_manager.get_session() as session:
    # Read operations
    entity = entity_repo.get_by_id(session, entity_id)

# Transaction management
with db_manager.get_transaction() as session:
    # Write operations with automatic commit/rollback
    entity = entity_repo.create(session=session, name="Test")

# Health check
is_healthy = await db_manager.health_check()
print(f"Database healthy: {is_healthy}")

# Connection info
info = db_manager.get_connection_info()
print(f"Connected to: {info['host']}:{info['port']}")
```

## Migration Management

```python
from src.{{service_package}}.app.core.migrations import get_migration_manager

migration_manager = get_migration_manager()

# Check if migrations needed
if migration_manager.is_migration_needed():
    print("Migrations needed")

    # Apply migrations
    success = migration_manager.upgrade_to_head()
    if success:
        print("Migrations applied successfully")

# Create new migration
migration_manager.create_migration("Add new field", autogenerate=True)

# Get migration history
history = migration_manager.get_migration_history()
for rev in history:
    print(f"Revision: {rev['revision']} - {rev['doc']}")
```

## Configuration Options

```python
class DatabaseServiceConfig(GRPCServiceConfig):
    # Database connection
    database_url: str = "postgresql://localhost:5432/{{service_package}}_db"
    database_pool_size: int = 10
    database_max_overflow: int = 20
    database_pool_timeout: int = 30
    database_pool_recycle: int = 3600

    # Connection health
    database_health_check_interval: int = 30
    database_max_retries: int = 3
    database_retry_delay: float = 1.0

    # Migration settings
    auto_migrate_on_startup: bool = True
    migration_timeout: int = 300

    # Query settings
    database_echo: bool = False
    database_echo_pool: bool = False
    query_timeout: int = 30
```

## Testing

```python
import pytest
from src.{{service_package}}.app.core.database import get_database_manager

@pytest.fixture
async def db_manager():
    manager = get_database_manager()
    await manager.create_tables()
    yield manager
    await manager.drop_tables()

@pytest.mark.asyncio
async def test_entity_creation(db_manager):
    entity_repo = get_entity_repository()

    with db_manager.get_transaction() as session:
        entity = entity_repo.create(
            session=session,
            name="Test Entity",
            status="active"
        )
        assert entity.id is not None
        assert entity.name == "Test Entity"
```

## Best Practices

### 1. Always Use Transactions for Writes
```python
# Good
with db_manager.get_transaction() as session:
    entity = entity_repo.create(session=session, name="Test")
    attribute_repo.create(session=session, entity_id=entity.id, ...)

# Avoid
with db_manager.get_session() as session:
    entity = entity_repo.create(session=session, name="Test")  # No auto-commit
```

### 2. Use Repository Pattern
```python
# Good
entity = entity_repo.get_by_id(session, entity_id)

# Avoid direct SQLAlchemy queries
entity = session.query({{service_class}}Entity).filter(...).first()
```

### 3. Enable Audit Logging
```python
# Log all changes in service layer
audit_repo.log_change(
    session=session,
    entity_id=entity.id,
    entity_type="{{service_class}}Entity",
    action="CREATE",
    new_values={"name": entity.name},
    user_id=get_user_id(context),
    session_id=get_session_id(context)
)
```

### 4. Handle Soft Deletes
```python
# Default to soft delete
entity_repo.delete(session, entity_id, soft_delete=True)

# Use include_deleted when needed
entity = entity_repo.get_by_id(session, entity_id, include_deleted=True)
```

### 5. Use Pagination for Large Results
```python
# Good
entities = entity_repo.get_all(session, skip=0, limit=100)

# Avoid
entities = entity_repo.get_all(session)  # Could return millions
```

## Monitoring

The service includes comprehensive health checks:

```python
# Database connectivity
health = await db_manager.health_check()

# Connection pool status
info = db_manager.get_connection_info()

# Migration status
migration_manager = get_migration_manager()
current_rev = migration_manager.get_current_revision()
head_rev = migration_manager.get_head_revision()
```

## Security

- All queries use parameterized statements (SQLAlchemy ORM)
- Connection pooling prevents connection exhaustion
- Audit logging tracks all data changes
- Soft deletes prevent accidental data loss
- Transaction isolation prevents race conditions

## Performance

- Connection pooling for database efficiency
- Indexed columns for fast queries
- Pagination to limit result sets
- Optimistic locking to prevent conflicts
- Query timeout prevention
- Pool overflow handling
