"""
Redis Manager for Message Queue Service
"""

import asyncio
import logging
import json
from typing import Optional, Dict, Any, List, Callable, Union
from datetime import datetime, timezone
import uuid

import redis.asyncio as redis
from redis.exceptions import RedisError, ConnectionError

from src.{{service_package}}.app.core.config import {{service_class}}ServiceConfig
from src.{{service_package}}.app.core.models import Message, MessageMetadata

logger = logging.getLogger(__name__)


class RedisManager:
    """Manages Redis connections and operations for streams and pub/sub."""

    def __init__(self, config: {{service_class}}ServiceConfig):
        """Initialize the Redis manager."""
        self.config = config
        self.redis_client: Optional[redis.Redis] = None
        self.pubsub_client: Optional[redis.Redis] = None
        self.consumers: Dict[str, Dict[str, Any]] = {}
        self.is_initialized = False

    async def initialize(self) -> None:
        """Initialize Redis connections."""
        if not self.config.redis_enabled:
            logger.warning("Redis is not enabled")
            return

        try:
            logger.info("Initializing Redis manager...")

            # Create Redis clients
            await self._create_clients()

            # Test connections
            await self._test_connections()

            # Create streams if configured
            await self._create_streams()

            self.is_initialized = True
            logger.info("Redis manager initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize Redis manager: {e}")
            raise

    async def _create_clients(self) -> None:
        """Create Redis clients."""
        try:
            redis_config = self.config.get_redis_config()

            # Create main Redis client
            self.redis_client = redis.Redis(
                host=redis_config.get('host', 'localhost'),
                port=redis_config.get('port', 6379),
                db=redis_config.get('db', 0),
                password=redis_config.get('password'),
                username=redis_config.get('username'),
                ssl=redis_config.get('ssl', False),
                ssl_cert_reqs=redis_config.get('ssl_cert_reqs'),
                ssl_ca_certs=redis_config.get('ssl_ca_certs'),
                ssl_certfile=redis_config.get('ssl_certfile'),
                ssl_keyfile=redis_config.get('ssl_keyfile'),
                max_connections=redis_config.get('max_connections', 10),
                retry_on_timeout=redis_config.get('retry_on_timeout', True),
                socket_timeout=redis_config.get('socket_timeout', 30),
                socket_connect_timeout=redis_config.get('socket_connect_timeout', 30),
                decode_responses=False  # We'll handle encoding/decoding manually
            )

            # Create separate client for pub/sub operations
            pubsub_config = redis_config.copy()
            pubsub_config['max_connections'] = 1  # Pub/sub needs dedicated connection

            self.pubsub_client = redis.Redis(
                host=pubsub_config.get('host', 'localhost'),
                port=pubsub_config.get('port', 6379),
                db=pubsub_config.get('db', 0),
                password=pubsub_config.get('password'),
                username=pubsub_config.get('username'),
                ssl=pubsub_config.get('ssl', False),
                ssl_cert_reqs=pubsub_config.get('ssl_cert_reqs'),
                ssl_ca_certs=pubsub_config.get('ssl_ca_certs'),
                ssl_certfile=pubsub_config.get('ssl_certfile'),
                ssl_keyfile=pubsub_config.get('ssl_keyfile'),
                max_connections=1,
                retry_on_timeout=pubsub_config.get('retry_on_timeout', True),
                socket_timeout=pubsub_config.get('socket_timeout', 30),
                socket_connect_timeout=pubsub_config.get('socket_connect_timeout', 30),
                decode_responses=False
            )

            logger.info("Redis clients created")

        except Exception as e:
            logger.error(f"Failed to create Redis clients: {e}")
            raise

    async def _test_connections(self) -> None:
        """Test Redis connections."""
        try:
            # Test main client
            await self.redis_client.ping()
            logger.info("Redis main client connection verified")

            # Test pub/sub client
            await self.pubsub_client.ping()
            logger.info("Redis pub/sub client connection verified")

        except Exception as e:
            logger.error(f"Failed to verify Redis connections: {e}")
            raise

    async def _create_streams(self) -> None:
        """Create Redis streams if they don't exist."""
        try:
            stream_configs = self.config.get_stream_configs()

            for stream_config in stream_configs:
                stream_name = stream_config["name"]

                try:
                    # Check if stream exists
                    await self.redis_client.xinfo_stream(stream_name)
                    logger.debug(f"Stream {stream_name} already exists")
                except redis.ResponseError:
                    # Stream doesn't exist, create it with a dummy message
                    await self.redis_client.xadd(
                        stream_name,
                        {"_init": "stream_created"},
                        id="0-1"
                    )

                    # Delete the dummy message
                    await self.redis_client.xdel(stream_name, "0-1")

                    logger.info(f"Created Redis stream: {stream_name}")

                # Create consumer groups if configured
                for group_config in stream_config.get("consumer_groups", []):
                    group_name = group_config["name"]
                    start_id = group_config.get("start_id", "$")

                    try:
                        await self.redis_client.xgroup_create(
                            stream_name,
                            group_name,
                            id=start_id,
                            mkstream=True
                        )
                        logger.info(f"Created consumer group {group_name} for stream {stream_name}")
                    except redis.ResponseError as e:
                        if "BUSYGROUP" in str(e):
                            logger.debug(f"Consumer group {group_name} already exists for stream {stream_name}")
                        else:
                            logger.error(f"Failed to create consumer group {group_name}: {e}")

        except Exception as e:
            logger.error(f"Failed to create Redis streams: {e}")
            # Don't raise here as streams might already exist

    # Stream Operations

    async def add_to_stream(
        self,
        stream_name: str,
        message: Message,
        message_id: Optional[str] = None,
        maxlen: Optional[int] = None,
        approximate: bool = True
    ) -> str:
        """Add a message to Redis stream.

        Args:
            stream_name: Stream name
            message: Message to add
            message_id: Specific message ID (optional, auto-generated if not provided)
            maxlen: Maximum stream length for trimming
            approximate: Use approximate trimming

        Returns:
            Message ID in the stream
        """
        try:
            # Prepare message data
            message_data = {
                "id": message.id,
                "type": message.type,
                "data": json.dumps(message.data, default=str),
                "metadata": json.dumps({
                    "timestamp": message.metadata.timestamp.isoformat(),
                    "source": message.metadata.source,
                    "version": message.metadata.version,
                    "correlation_id": message.metadata.correlation_id,
                    "causation_id": message.metadata.causation_id,
                    "user_id": message.metadata.user_id,
                    "session_id": message.metadata.session_id,
                    "trace_id": message.metadata.trace_id,
                    "span_id": message.metadata.span_id,
                    "headers": message.metadata.headers,
                    "tags": message.metadata.tags
                }, default=str)
            }

            # Add to stream
            stream_id = await self.redis_client.xadd(
                stream_name,
                message_data,
                id=message_id or "*",
                maxlen=maxlen,
                approximate=approximate
            )

            logger.debug(f"Added message {message.id} to stream {stream_name} with ID {stream_id}")
            return stream_id.decode('utf-8') if isinstance(stream_id, bytes) else stream_id

        except Exception as e:
            logger.error(f"Failed to add message to stream {stream_name}: {e}")
            raise

    async def read_from_stream(
        self,
        stream_name: str,
        start_id: str = "0",
        count: Optional[int] = None,
        block: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """Read messages from Redis stream.

        Args:
            stream_name: Stream name
            start_id: Starting message ID
            count: Maximum number of messages
            block: Block for specified milliseconds if no messages

        Returns:
            List of messages with metadata
        """
        try:
            # Read from stream
            if block is not None:
                result = await self.redis_client.xread(
                    {stream_name: start_id},
                    count=count,
                    block=block
                )
            else:
                result = await self.redis_client.xread(
                    {stream_name: start_id},
                    count=count
                )

            messages = []
            for stream, stream_messages in result:
                for message_id, fields in stream_messages:
                    try:
                        message = self._redis_stream_to_message(message_id, fields)
                        messages.append({
                            "stream_id": message_id.decode('utf-8') if isinstance(message_id, bytes) else message_id,
                            "message": message
                        })
                    except Exception as e:
                        logger.error(f"Failed to parse stream message {message_id}: {e}")
                        continue

            return messages

        except Exception as e:
            logger.error(f"Failed to read from stream {stream_name}: {e}")
            return []

    async def consume_from_stream_group(
        self,
        stream_name: str,
        group_name: str,
        consumer_name: str,
        message_handler: Callable[[Message], bool],
        count: Optional[int] = None,
        block: Optional[int] = None
    ) -> None:
        """Consume messages from Redis stream using consumer group.

        Args:
            stream_name: Stream name
            group_name: Consumer group name
            consumer_name: Consumer name
            message_handler: Function to handle each message
            count: Maximum messages per read
            block: Block time in milliseconds
        """
        try:
            logger.info(f"Starting stream consumption: {stream_name}/{group_name}/{consumer_name}")

            while True:
                try:
                    # Read new messages
                    result = await self.redis_client.xreadgroup(
                        group_name,
                        consumer_name,
                        {stream_name: ">"},
                        count=count or 10,
                        block=block or 1000
                    )

                    for stream, messages in result:
                        for message_id, fields in messages:
                            try:
                                # Convert to our Message format
                                message = self._redis_stream_to_message(message_id, fields)

                                # Handle the message
                                success = await self._handle_message_with_retry(message, message_handler)

                                if success:
                                    # Acknowledge the message
                                    await self.redis_client.xack(stream_name, group_name, message_id)
                                else:
                                    logger.error(f"Failed to process message after retries: {message.id}")
                                    await self._send_to_dlq(message, stream_name)
                                    await self.redis_client.xack(stream_name, group_name, message_id)

                            except Exception as e:
                                logger.error(f"Error processing stream message {message_id}: {e}")
                                continue

                    # Process pending messages (messages that were delivered but not acknowledged)
                    await self._process_pending_messages(stream_name, group_name, consumer_name, message_handler)

                except redis.ResponseError as e:
                    if "NOGROUP" in str(e):
                        logger.error(f"Consumer group {group_name} does not exist for stream {stream_name}")
                        break
                    else:
                        logger.error(f"Redis error in stream consumption: {e}")
                        await asyncio.sleep(1)
                        continue

                except Exception as e:
                    logger.error(f"Error in stream consumption: {e}")
                    await asyncio.sleep(1)
                    continue

        except Exception as e:
            logger.error(f"Fatal error in stream consumption: {e}")
            raise

    async def _process_pending_messages(
        self,
        stream_name: str,
        group_name: str,
        consumer_name: str,
        message_handler: Callable[[Message], bool]
    ) -> None:
        """Process pending messages for a consumer."""
        try:
            # Get pending messages for this consumer
            pending = await self.redis_client.xpending_range(
                stream_name,
                group_name,
                min="-",
                max="+",
                count=100,
                consumer=consumer_name
            )

            if not pending:
                return

            # Claim old pending messages (older than 5 minutes)
            min_idle_time = 5 * 60 * 1000  # 5 minutes in milliseconds
            message_ids = [msg['message_id'] for msg in pending if msg['time_since_delivered'] > min_idle_time]

            if message_ids:
                claimed = await self.redis_client.xclaim(
                    stream_name,
                    group_name,
                    consumer_name,
                    min_idle_time,
                    message_ids
                )

                for message_id, fields in claimed:
                    try:
                        message = self._redis_stream_to_message(message_id, fields)
                        success = await self._handle_message_with_retry(message, message_handler)

                        if success:
                            await self.redis_client.xack(stream_name, group_name, message_id)
                        else:
                            await self._send_to_dlq(message, stream_name)
                            await self.redis_client.xack(stream_name, group_name, message_id)

                    except Exception as e:
                        logger.error(f"Error processing claimed message {message_id}: {e}")
                        continue

        except Exception as e:
            logger.error(f"Error processing pending messages: {e}")

    # Pub/Sub Operations

    async def publish_message(
        self,
        channel: str,
        message: Message
    ) -> int:
        """Publish a message to Redis channel.

        Args:
            channel: Channel name
            message: Message to publish

        Returns:
            Number of subscribers that received the message
        """
        try:
            # Prepare message payload
            payload = {
                "id": message.id,
                "type": message.type,
                "data": message.data,
                "metadata": {
                    "timestamp": message.metadata.timestamp.isoformat(),
                    "source": message.metadata.source,
                    "version": message.metadata.version,
                    "correlation_id": message.metadata.correlation_id,
                    "causation_id": message.metadata.causation_id,
                    "user_id": message.metadata.user_id,
                    "session_id": message.metadata.session_id,
                    "trace_id": message.metadata.trace_id,
                    "span_id": message.metadata.span_id,
                    "headers": message.metadata.headers,
                    "tags": message.metadata.tags
                }
            }

            # Publish message
            subscribers = await self.redis_client.publish(
                channel,
                json.dumps(payload, default=str)
            )

            logger.debug(f"Published message {message.id} to channel {channel}, reached {subscribers} subscribers")
            return subscribers

        except Exception as e:
            logger.error(f"Failed to publish message to channel {channel}: {e}")
            return 0

    async def subscribe_to_channels(
        self,
        channels: List[str],
        message_handler: Callable[[str, Message], bool],
        patterns: bool = False
    ) -> None:
        """Subscribe to Redis channels.

        Args:
            channels: List of channels to subscribe to
            message_handler: Function to handle each message (receives channel and message)
            patterns: Whether channels are patterns
        """
        try:
            pubsub = self.pubsub_client.pubsub()

            if patterns:
                await pubsub.psubscribe(*channels)
                logger.info(f"Subscribed to channel patterns: {channels}")
            else:
                await pubsub.subscribe(*channels)
                logger.info(f"Subscribed to channels: {channels}")

            # Process messages
            async for redis_message in pubsub.listen():
                try:
                    if redis_message['type'] not in ['message', 'pmessage']:
                        continue

                    channel = redis_message['channel'].decode('utf-8') if isinstance(redis_message['channel'], bytes) else redis_message['channel']
                    data = redis_message['data']

                    if isinstance(data, bytes):
                        data = data.decode('utf-8')

                    # Parse message
                    payload = json.loads(data)
                    message = self._redis_pubsub_to_message(payload)

                    # Handle the message
                    await self._handle_message_with_retry(
                        message,
                        lambda msg: message_handler(channel, msg)
                    )

                except Exception as e:
                    logger.error(f"Error processing pub/sub message: {e}")
                    continue

        except Exception as e:
            logger.error(f"Error in pub/sub subscription: {e}")
            raise

    def _redis_stream_to_message(self, message_id: Union[str, bytes], fields: Dict) -> Message:
        """Convert Redis stream message to our Message format."""
        # Decode fields if they are bytes
        decoded_fields = {}
        for key, value in fields.items():
            key = key.decode('utf-8') if isinstance(key, bytes) else key
            value = value.decode('utf-8') if isinstance(value, bytes) else value
            decoded_fields[key] = value

        metadata_data = json.loads(decoded_fields["metadata"])

        metadata = MessageMetadata(
            timestamp=datetime.fromisoformat(metadata_data["timestamp"]),
            source=metadata_data["source"],
            version=metadata_data["version"],
            correlation_id=metadata_data["correlation_id"],
            causation_id=metadata_data["causation_id"],
            user_id=metadata_data["user_id"],
            session_id=metadata_data["session_id"],
            trace_id=metadata_data["trace_id"],
            span_id=metadata_data["span_id"],
            headers=metadata_data["headers"],
            tags=metadata_data["tags"]
        )

        return Message(
            id=decoded_fields["id"],
            type=decoded_fields["type"],
            data=json.loads(decoded_fields["data"]),
            metadata=metadata
        )

    def _redis_pubsub_to_message(self, payload: Dict) -> Message:
        """Convert Redis pub/sub message to our Message format."""
        metadata = MessageMetadata(
            timestamp=datetime.fromisoformat(payload["metadata"]["timestamp"]),
            source=payload["metadata"]["source"],
            version=payload["metadata"]["version"],
            correlation_id=payload["metadata"]["correlation_id"],
            causation_id=payload["metadata"]["causation_id"],
            user_id=payload["metadata"]["user_id"],
            session_id=payload["metadata"]["session_id"],
            trace_id=payload["metadata"]["trace_id"],
            span_id=payload["metadata"]["span_id"],
            headers=payload["metadata"]["headers"],
            tags=payload["metadata"]["tags"]
        )

        return Message(
            id=payload["id"],
            type=payload["type"],
            data=payload["data"],
            metadata=metadata
        )

    async def _handle_message_with_retry(
        self,
        message: Message,
        handler: Callable[[Message], bool],
        max_retries: Optional[int] = None
    ) -> bool:
        """Handle message with retry logic."""
        max_retries = max_retries or self.config.message_retry_attempts
        delay = self.config.message_retry_delay_ms / 1000.0

        for attempt in range(max_retries + 1):
            try:
                success = handler(message)
                if success:
                    return True

                if attempt < max_retries:
                    logger.warning(f"Message processing failed, retrying in {delay}s (attempt {attempt + 1}/{max_retries})")
                    await asyncio.sleep(delay)
                    delay = min(delay * self.config.message_retry_backoff_multiplier,
                              self.config.message_max_retry_delay_ms / 1000.0)

            except Exception as e:
                logger.error(f"Error handling message (attempt {attempt + 1}): {e}")
                if attempt < max_retries:
                    await asyncio.sleep(delay)
                    delay = min(delay * self.config.message_retry_backoff_multiplier,
                              self.config.message_max_retry_delay_ms / 1000.0)

        return False

    async def _send_to_dlq(self, message: Message, original_stream: str) -> None:
        """Send message to dead letter queue."""
        if not self.config.dlq_enabled:
            return

        dlq_stream = f"{original_stream}{self.config.dlq_stream_suffix}"

        # Add DLQ metadata
        message.metadata.headers = message.metadata.headers or {}
        message.metadata.headers.update({
            "original_stream": original_stream,
            "dlq_timestamp": datetime.now(timezone.utc).isoformat(),
            "failure_reason": "max_retries_exceeded"
        })

        await self.add_to_stream(dlq_stream, message)
        logger.info(f"Message {message.id} sent to DLQ stream: {dlq_stream}")

    async def get_stream_info(self, stream_name: str) -> Dict[str, Any]:
        """Get information about a Redis stream."""
        try:
            info = await self.redis_client.xinfo_stream(stream_name)
            return {
                "length": info.get(b"length", 0),
                "first_entry": info.get(b"first-entry"),
                "last_entry": info.get(b"last-entry"),
                "consumer_groups": info.get(b"groups", 0)
            }
        except Exception as e:
            logger.error(f"Failed to get stream info for {stream_name}: {e}")
            return {}

    async def trim_stream(self, stream_name: str, maxlen: int, approximate: bool = True) -> int:
        """Trim a Redis stream to specified length.

        Returns:
            Number of messages removed
        """
        try:
            result = await self.redis_client.xtrim(stream_name, maxlen, approximate=approximate)
            logger.info(f"Trimmed stream {stream_name} to {maxlen} messages, removed {result}")
            return result
        except Exception as e:
            logger.error(f"Failed to trim stream {stream_name}: {e}")
            return 0

    async def shutdown(self) -> None:
        """Shutdown Redis connections."""
        logger.info("Shutting down Redis manager...")

        try:
            # Clear consumers
            self.consumers.clear()

            # Close Redis clients
            if self.redis_client:
                await self.redis_client.close()
                logger.debug("Closed Redis main client")

            if self.pubsub_client:
                await self.pubsub_client.close()
                logger.debug("Closed Redis pub/sub client")

            self.is_initialized = False
            logger.info("Redis manager shutdown complete")

        except Exception as e:
            logger.error(f"Error during Redis shutdown: {e}")


# Global Redis manager instance
_redis_manager: Optional[RedisManager] = None


def get_redis_manager() -> RedisManager:
    """Get the global Redis manager instance."""
    global _redis_manager
    if _redis_manager is None:
        config = {{service_class}}ServiceConfig()
        _redis_manager = RedisManager(config)
    return _redis_manager
