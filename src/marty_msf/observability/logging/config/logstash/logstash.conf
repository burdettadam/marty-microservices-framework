# Logstash Configuration for Marty Microservices Framework
# Processes structured logs from microservices and routes to Elasticsearch

input {
  # Beats input (Filebeat)
  beats {
    port => 5044
    type => "beats"
  }

  # Direct TCP JSON input for applications
  tcp {
    port => 5000
    codec => json_lines
    type => "json_tcp"
  }

  # HTTP input for webhook-style log ingestion
  http {
    port => 8080
    codec => json
    type => "http_webhook"
  }

  # Redis input for buffered logs
  redis {
    host => "redis-logs"
    port => 6379
    key => "logstash:logs"
    data_type => "list"
    codec => json
    type => "redis_buffer"
  }

  # Syslog input
  syslog {
    port => 514
    type => "syslog"
  }

  # Docker logs via journald
  journald {
    type => "journald"
    path => "/var/log/journal"
  }
}

filter {
  # Parse timestamp fields
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }

  # Parse Kubernetes metadata
  if [kubernetes] {
    mutate {
      add_field => {
        "k8s_namespace" => "%{[kubernetes][namespace]}"
        "k8s_pod" => "%{[kubernetes][pod]}"
        "k8s_container" => "%{[kubernetes][container]}"
        "k8s_node" => "%{[kubernetes][node]}"
      }
    }
  }

  # Parse Docker container metadata
  if [container] {
    mutate {
      add_field => {
        "container_id" => "%{[container][id]}"
        "container_name" => "%{[container][name]}"
        "container_image" => "%{[container][image]}"
      }
    }
  }

  # Enhanced service detection
  if ![service_name] and [kubernetes][labels][app] {
    mutate {
      add_field => { "service_name" => "%{[kubernetes][labels][app]}" }
    }
  }

  if ![service_name] and [container][labels][service] {
    mutate {
      add_field => { "service_name" => "%{[container][labels][service]}" }
    }
  }

  # Default service name if not detected
  if ![service_name] {
    mutate {
      add_field => { "service_name" => "unknown" }
    }
  }

  # Parse JSON logs from application containers
  if [type] == "beats" and [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "structured"
      remove_field => ["message"]
    }

    # Extract structured fields to top level
    if [structured] {
      ruby {
        code => "
          structured = event.get('structured')
          if structured.is_a?(Hash)
            structured.each do |key, value|
              unless ['@timestamp', '@version', 'type', 'tags'].include?(key)
                event.set(key, value)
              end
            end
          end
        "
      }
      mutate {
        remove_field => ["structured"]
      }
    }
  }

  # Parse standard log levels
  if [level] {
    mutate {
      uppercase => ["level"]
    }
  } else if [severity] {
    mutate {
      add_field => { "level" => "%{severity}" }
      uppercase => ["level"]
    }
  }

  # Categorize logs
  if ![category] {
    if [level] == "ERROR" or [level] == "CRITICAL" or [level] == "FATAL" {
      mutate {
        add_field => { "category" => "error" }
      }
    } else if [http_method] or [response_time_ms] or [http_status] {
      mutate {
        add_field => { "category" => "access" }
      }
    } else if [security_event] or [authentication] or [authorization] {
      mutate {
        add_field => { "category" => "security" }
      }
    } else if [duration_ms] or [performance] {
      mutate {
        add_field => { "category" => "performance" }
      }
    } else if [business] or [event_type] {
      mutate {
        add_field => { "category" => "business" }
      }
    } else {
      mutate {
        add_field => { "category" => "application" }
      }
    }
  }

  # Add processing metadata
  mutate {
    add_field => {
      "processed_at" => "%{+YYYY-MM-dd'T'HH:mm:ss.SSSZ}"
      "logstash_host" => "%{[host][name]}"
      "pipeline_version" => "1.0.0"
    }
  }

  # Enhance error logs
  if [level] in ["ERROR", "CRITICAL", "FATAL"] and [error] {
    if [error][stack_trace] {
      mutate {
        add_field => { "has_stack_trace" => true }
      }
    }

    if [error][type] {
      mutate {
        add_field => { "error_type" => "%{[error][type]}" }
      }
    }
  }

  # Performance metrics extraction
  if [performance] or [duration_ms] {
    if [duration_ms] {
      ruby {
        code => "
          duration = event.get('duration_ms')
          if duration.is_a?(Numeric)
            if duration > 5000
              event.set('performance_tier', 'slow')
            elsif duration > 1000
              event.set('performance_tier', 'medium')
            else
              event.set('performance_tier', 'fast')
            end
          end
        "
      }
    }
  }

  # Business metrics extraction
  if [business] {
    if [business][amount] and [business][currency] {
      mutate {
        add_field => {
          "business_amount" => "%{[business][amount]}"
          "business_currency" => "%{[business][currency]}"
        }
      }
    }

    if [business][event_type] {
      mutate {
        add_field => { "business_event_type" => "%{[business][event_type]}" }
      }
    }
  }

  # Security event enhancement
  if [category] == "security" {
    if [source_ip] {
      # GeoIP lookup
      geoip {
        source => "source_ip"
        target => "geoip"
      }
    }

    mutate {
      add_field => { "security_priority" => "high" }
    }

    if [security_event] in ["authentication_failure", "unauthorized_access", "suspicious_activity"] {
      mutate {
        replace => { "security_priority" => "critical" }
      }
    }
  }

  # HTTP access log enhancement
  if [http_status] {
    ruby {
      code => "
        status = event.get('http_status')
        if status.is_a?(Numeric)
          if status >= 500
            event.set('http_status_class', '5xx')
            event.set('http_error_type', 'server_error')
          elsif status >= 400
            event.set('http_status_class', '4xx')
            event.set('http_error_type', 'client_error')
          elsif status >= 300
            event.set('http_status_class', '3xx')
          elsif status >= 200
            event.set('http_status_class', '2xx')
          else
            event.set('http_status_class', '1xx')
          end
        end
      "
    }
  }

  # Trace context enhancement
  if [trace_id] and [span_id] {
    mutate {
      add_field => {
        "has_trace_context" => true
        "trace_url" => "http://jaeger:16686/trace/%{trace_id}"
      }
    }
  }

  # User context enhancement
  if [user_id] {
    mutate {
      add_field => { "has_user_context" => true }
    }
  }

  # Clean up fields
  mutate {
    remove_field => [
      "agent",
      "ecs",
      "input",
      "log",
      "@version"
    ]
  }

  # Add fingerprint for deduplication
  fingerprint {
    source => ["service_name", "level", "message", "timestamp"]
    target => "[@metadata][fingerprint]"
    method => "SHA256"
  }
}

output {
  # Main Elasticsearch output
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]

    # Dynamic index naming based on service and date
    index => "marty-logs-%{service_name}-%{+YYYY.MM.dd}"

    # Use fingerprint for document ID to handle duplicates
    document_id => "%{[@metadata][fingerprint]}"

    # Template management
    manage_template => true
    template_name => "marty-logs"
    template => "/usr/share/logstash/templates/marty-logs-template.json"
    template_overwrite => true

    # Bulk settings for performance
    flush_size => 1000
    idle_flush_time => 5
  }

  # Error logs to separate index
  if [level] in ["ERROR", "CRITICAL", "FATAL"] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "marty-errors-%{+YYYY.MM.dd}"
      document_id => "%{[@metadata][fingerprint]}-error"
    }
  }

  # Security logs to separate index
  if [category] == "security" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "marty-security-%{+YYYY.MM.dd}"
      document_id => "%{[@metadata][fingerprint]}-security"
    }
  }

  # Business logs to separate index
  if [category] == "business" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "marty-business-%{+YYYY.MM.dd}"
      document_id => "%{[@metadata][fingerprint]}-business"
    }
  }

  # Performance logs to separate index
  if [category] == "performance" or [duration_ms] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "marty-performance-%{+YYYY.MM.dd}"
      document_id => "%{[@metadata][fingerprint]}-performance"
    }
  }

  # High-priority alerts to Redis for real-time processing
  if [level] == "CRITICAL" or [security_priority] == "critical" {
    redis {
      host => "redis-logs"
      port => 6379
      key => "alerts:critical"
      data_type => "list"
      codec => json
    }
  }

  # Debug output for development
  # Uncomment for troubleshooting
  # stdout {
  #   codec => rubydebug
  # }
}
