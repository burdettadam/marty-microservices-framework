#!/usr/bin/env python3
"""
Local Kafka Integration Test for Petstore Domain
Tests Kafka integration with localhost broker for local development
"""
import asyncio
import logging
import os
import sys
from pathlib import Path

# Add the app directory to the path so we can import our modules
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.services.event_service import EventService

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_local_kafka():
    """Test Kafka with localhost broker"""
    # Override environment to use localhost
    os.environ["KAFKA_BROKERS"] = "localhost:9092"

    logger.info("üîå Testing LOCAL Kafka connection (localhost:9092)...")

    event_service = EventService()

    try:
        await event_service.start()
        logger.info("‚úÖ Successfully connected to local Kafka")

        # Test publishing events
        await test_events(event_service)

        logger.info("‚úÖ All local Kafka tests completed successfully")
        return True

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Local Kafka connection failed (expected if no local Kafka): {e}")
        logger.info("‚ÑπÔ∏è  This is normal if you don't have Kafka running locally")
        return False
    finally:
        await event_service.stop()
        logger.info("üîå Local Kafka connection closed")


async def test_production_config():
    """Test production configuration without connecting"""
    # Reset to production config
    if "KAFKA_BROKERS" in os.environ:
        del os.environ["KAFKA_BROKERS"]

    logger.info("üîß Testing PRODUCTION Kafka configuration...")

    event_service = EventService()

    # Test configuration without connecting
    expected_broker = "kafka.observability.svc.cluster.local:9092"
    actual_broker = event_service.kafka_brokers

    if actual_broker == expected_broker:
        logger.info(f"‚úÖ Production broker configuration correct: {actual_broker}")
    else:
        logger.error(f"‚ùå Production broker configuration incorrect: {actual_broker}")
        return False

    expected_prefix = "petstore"
    actual_prefix = event_service.topic_prefix

    if actual_prefix == expected_prefix:
        logger.info(f"‚úÖ Topic prefix configuration correct: {actual_prefix}")
    else:
        logger.error(f"‚ùå Topic prefix configuration incorrect: {actual_prefix}")
        return False

    logger.info("‚úÖ Production configuration validation passed")
    return True


async def test_events(event_service: EventService):
    """Test event publishing"""
    logger.info("üì¶ Testing event publishing...")

    # Test order event
    success = await event_service.publish_order_event(
        order_id="ORDER-TEST-001",
        event_type="created",
        order_data={
            "customer_id": "CUSTOMER-123",
            "pet_id": "PET-456",
            "quantity": 2,
            "total_amount": 199.98
        }
    )

    if success:
        logger.info("‚úÖ Order event published successfully")
    else:
        logger.error("‚ùå Failed to publish order event")

    # Test pet event
    success = await event_service.publish_pet_event(
        pet_id="PET-TEST-001",
        event_type="adoption_requested",
        pet_data={
            "breed": "Golden Retriever",
            "age": 2,
            "customer_id": "CUSTOMER-123"
        }
    )

    if success:
        logger.info("‚úÖ Pet event published successfully")
    else:
        logger.error("‚ùå Failed to publish pet event")


def test_import_functionality():
    """Test that all imports work correctly"""
    logger.info("üìö Testing import functionality...")

    try:
        from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
        logger.info("‚úÖ aiokafka imports successful")
    except ImportError as e:
        logger.error(f"‚ùå aiokafka import failed: {e}")
        return False

    try:
        from confluent_kafka import Producer
        logger.info("‚úÖ confluent-kafka imports successful")
    except ImportError as e:
        logger.error(f"‚ùå confluent-kafka import failed: {e}")
        return False

    logger.info("‚úÖ All Kafka dependencies imported successfully")
    return True


async def main():
    """Main demo function"""
    logger.info("üöÄ Starting Local Kafka Integration Test")
    logger.info("="*60)

    # Test imports first
    if not test_import_functionality():
        logger.error("‚ùå Import test failed")
        sys.exit(1)

    # Test production configuration
    config_success = await test_production_config()

    # Test local connection (may fail if no local Kafka)
    local_success = await test_local_kafka()

    logger.info("="*60)
    logger.info("üìä Test Results Summary:")
    logger.info(f"   Dependencies: ‚úÖ Installed")
    logger.info(f"   Production Config: {'‚úÖ Valid' if config_success else '‚ùå Invalid'}")
    logger.info(f"   Local Kafka Test: {'‚úÖ Connected' if local_success else '‚ö†Ô∏è  No local Kafka'}")

    if config_success:
        logger.info("üéâ Configuration validation successful!")
        logger.info("‚ÑπÔ∏è  The plugin is ready for Kafka integration in K8s environment")
        logger.info("‚ÑπÔ∏è  Expected broker: kafka.observability.svc.cluster.local:9092")
        logger.info("‚ÑπÔ∏è  Expected topics: petstore.order.*, petstore.pet.*, petstore.payment.*")
    else:
        logger.error("‚ùå Configuration validation failed")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
